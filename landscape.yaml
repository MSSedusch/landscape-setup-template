# Copyright (c) 2018 SAP SE or an SAP affiliate company. All rights reserved. This file is licensed under the Apache Software License, v. 2 except as noted otherwise in the LICENSE file
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This file contains parameters for setting up a minimal Gardener 
# environment. Follow the instructions in the file to configure an 
# installation

# Note: the purpose of this project is to provide a simple setup of the 
#       Gardener environment. It is not meant for productive environments


cloud:
  # currently only AWS and Openstack are supported, other cloud providers will follow
  # for this setup (Azure, GCP, ...)
  # Use lower case!
  variant: <cloud variant>

authentication:
  # for gardener installation on AWS
  variant_aws:
    # You need an AWS access key which has sufficient permissions to create a
    # VPC, subnets, routing tables, VMs, etc.
    aws_access_key: &aws_access_key "<access key>"
    aws_secret_key: &aws_secret_key "<secret key>"
    # AWS region where the Kubify cluster will be created
    aws_region: eu-west-1
    # Availability zone for the Kubify cluster
    aws_availability_zone: b
  # for gardener installation on OpenStack
  variant_openstack:
    os_user_name: "<openstack username>"
    os_password: "<openstack password>"
    os_auth_url: "<openstack v3 api endpoint>"
    os_tenant_name: "<tenant/project name>"
    os_domain_name: "<domain name>"
    os_region: "<region name>"
    os_az: "<availability zone>"

# ---------------------------------------------------------------------------
# Settings required for Kubernetes cluster setup with Kubify
# ---------------------------------------------------------------------------

# You should leave the following parameters untouched unless you are planning
# to use newer versions
versions:
  variant_all:
    kubernetes_version: v1.9.6
  variant_aws:
    etcd_version: v3.1.8
    image_name: "CoreOS-stable-1576.5.0"
  variant_openstack:
    image_name: "coreos-1688.5.3"

clusters:
  # name of the cluster
  name: "<cluster name>"
  type: eval
  dns:
    # domain name for cluster created by Kubify
    domain_name: "<full domain name for cluster>"
    # DNS provider (currently only route53 supported by these setup scripts)
    dns_type: route53
    # hosted zone for domain names and credentials (possibly the same ones
    # as above)
    hosted_zone_id: &hzone "<hosted zone id>"
    access_key: &hzone_access_key "<access key for hosted zone>"
    secret_key: &hzone_secret_key "<secret key for hosted zone>"
  master:
    # Properties for master nodes. 
    count: 3
    volume_size: 50
  worker:
    # Properties for worker nodes
    count: 3
    volume_size: 50

etcd_backup: 
  storage_type: s3
  region: eu-west-1

# for futher add-ons check the Kubify documentation
addons:
  variant_all:
    heapster: {}
    nginx-ingress: {}
    dashboard: 
      app_name: "kubernetes-dashboard"
  variant_aws: 
  variant_openstack:

misc: 
  variant_all:
    # use htpasswd to create password entries
    # example here: admin: ********* (htpasswd -bn admin "chosen password")
    dashboard_creds: "<credentials here>"
    # you should not change anything in this section below except for the 
    # password
    deploy_tiller: "false"
    oidc_issuer_subdomain: "identity.ingress"
    oidc_client_id: "kube-kubectl"
    oidc_username_claim: "email"
    oidc_groups_claim: "groups"
    oidc_ca_file: "/etc/kubernetes/secrets/ca.crt"
    subnet_cidr: &subnet_cidr "10.251.128.0/17"
    service_cidr: &service_cidr "10.241.0.0/17"
    pod_cidr: &pod_cidr "10.241.128.0/17"
    vpc_cidr: "10.251.0.0/16"
  variant_aws:
    aws_kube2iam_roles: 
    - name: example
      description: "Allow access to ECR repositories beginning with 'example/', and creation of new repositories"      
      policy: |
        {
              "Version": "2012-10-17",
              "Statement": [
                {
                  "Action": "ecr:*",
                  "Effect": "Allow",
                  "Resource": "arn:aws:ecr:eu-west-1:${account_id}:repository/example/*"
                },
                {
                  "Action": [
                    "ecr:GetAuthorizationToken",
                    "ecr:CreateRepository"
                  ],
                  "Effect": "Allow",
                  "Resource": "*"
                }
              ]
        }
  variant_openstack:
    os_fip_pool_name: "<floating ip pool name>"
    os_lbaas_provider: "haproxy"
    event_ttl: 730h0m0s

# ---------------------------------------------------------------------------
# Helm charts for gardener, dasboard, and identity deployments
# ---------------------------------------------------------------------------

charts:
- name: gardener
  repository: https://github.com/gardener/gardener
  path: charts/gardener
  tag: 0.3.1
  values:
    controller:
      internalDomain:
        # the cluster internal domain, this should be set to 
        # "internal." + clusters.dns.domain_name 
        domain: "<internal domain>"
        provider: aws-route53
        hostedZoneID: *hzone
        access_key: *hzone_access_key
        secret_key: *hzone_secret_key
      defaultDomains:
        # the cluster internal domain, this should be set to 
        # "shoot." + clusters.dns.domain_name 
      - domain: "<shoot domain>"
        provider: aws-route53
        hostedZoneID: *hzone
        access_key: *hzone_access_key
        secret_key: *hzone_secret_key
- name: dashboard
  repository: https://github.com/gardener/dashboard
  path: charts/gardener-dashboard
  tag: 1.7.0
- name: identity
  repository: https://github.com/gardener/dashboard
  path: charts/identity
  tag: v2.10.0
  values:
  # You need to set at least one password here to be able to 
  # log on. You can either provide the password in clear text 
  # in the "password" key or provide bcrypted passsword in
  # the "hash" key. Bcrypted password can be created with
  # htpasswd -bnBC 10 "" password | tr -d ':\n' | sed 's/$2y/$2a/'
  staticPasswords:
  # sample
  #- email: "dirk@**********"
  #  password: "***************"
  #  username: "admin"
  #  userID: "08a8684b-db88-4b73-90a9-3cd1661f5466"
  connectors:
  # Example for a GitHub connector below 
  # You will need to configure your GitHub account accordingly
  # see https://github.com/coreos/dex/blob/master/Documentation/connectors/github.md for further information on the GitHub connector
  # and https://github.com/coreos/dex/tree/master/Documentation/connectors for more connectors
#  - type: github
#    id: github
#    name: GitHub
#    config:
#      clientID: <github client id or environment variable containing it>
#      clientSecret: <github client secret or environment variable containing it>
      # redirectURI: <identity URL (with https!)>/callback
      # identity is usually located at identity.ingress. + clusters.dns.domain_name
#      redirectURI: <redirect URI>
      # Only users which are members of at least one organization can authenticate
#      orgs:
#      - name: <name of github organization>
- name: certmanager
  # Email address used for ACME registration
  email: "<email address>"

seed_config:
  variant_aws:
    # The cluster created by Kubify is registered as the seed cluster,
    # use the same region here as in the authentication node above
    region: "eu-west-1"
    # This is a Container Linux image. 
    # Note that ami ids differ between regions
    image: "ami-34237c4d"
    zones:
    - eu-west-1a
    - eu-west-1b
    - eu-west-1c
  variant_openstack:
    # The cluster created by Kubify is registered as the seed cluster,
    # use the same region here as in the authentication node above
    region: "<region name>"
    # This is a Container Linux image. 
    # The available images depend on your openstack setup
    image: "<image name>"
    # zones need to be adapted to the region
    zones:
    - <zone1>
    - <zone2>
    - <...>
  variant_all:
    node_cidr: *subnet_cidr
    pod_cidr: *pod_cidr
    service_cidr: *service_cidr
